{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "t = 0 #time\n",
    "Th = [] #collector of theta\n",
    "num_theta = 0 #num theta\n",
    "A = [] #collector of arm\n",
    "num_arms = 0 #number of arms\n",
    "K = 3 #dimension of arm x, y, theta\n",
    "Y = [] #collector of arm y\n",
    "num_arms_y = 0 #number of arms of player two\n",
    "M = [] #world\n",
    "num_M = 0\n",
    "M_vero = 0\n",
    "theta_vero = 0\n",
    "theta_stimato = [0, 0, 0, 0, 0, 0, 0, 0, 0] #stima di theta, start at 0,0,...,0\n",
    "double_arm = [] #collector of double arm\n",
    "num_double_arm = 0 #number of double arm\n",
    "R = [] #collection of reward\n",
    "Id_arm = [] #id of the double arm at time t associated to the reward\n",
    "played_superarm = [] #number of times each superarm is played\n",
    "num_best_super_arm = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0,0]\n",
    "num_second_best_super_arm = [0, 0, 0, 0, 0, 0, 0, 0, 0,0,0,0]\n",
    "final = [0, 0, 0, 0, 0, 0, 0, 0, 0,0,0,0]\n",
    "sample_correct = [0]*800 #correct at 10, 20, 50, 100, 200, 400, 600, 800\n",
    "error_reward = [0]*800\n",
    "error_best_choosen = [0] * 800\n",
    "\n",
    "delta = 0.05\n",
    "sigma = 0.1 #noise\n",
    "\n",
    "def norm_2_mat(x, V):\n",
    "    b = [x]\n",
    "    a = np.swapaxes(b, 0, 1)\n",
    "    ris = np.sqrt(np.matmul(np.matmul(b,V),a))\n",
    "    return ris[0][0]\n",
    "\n",
    "class world():\n",
    "    matrix = np.array([])\n",
    "    id\n",
    "\n",
    "    def __init__(self, param):\n",
    "        self.matrix = param\n",
    "        global M, num_M\n",
    "        self.id = num_M\n",
    "        M.append(self)\n",
    "        num_M +=1\n",
    "\n",
    "def create_union_arm(id_x, id_y):\n",
    "    res = []\n",
    "    for i in range(0, K):\n",
    "        for j in range(0, K):\n",
    "            res.append(A[id_x].arm_vector[i] * Y[id_y].arm_vector[j])\n",
    "    return res\n",
    "\n",
    "def create_all_union():\n",
    "    for i in range(0, num_arms):\n",
    "        for j in range (0, num_arms_y):\n",
    "            curr = create_union_arm(i, j)\n",
    "            double_arm.append(curr)\n",
    "            global num_double_arm\n",
    "            num_double_arm += 1\n",
    "            played_superarm.append(0)\n",
    "\n",
    "\n",
    "def calcola_A():\n",
    "    res = 0\n",
    "    for i in range(0, t):\n",
    "        #print(\"i\", i)\n",
    "        if i == 0:\n",
    "            #print(\"i==0, print res\", res)\n",
    "            #print(\" A[self.A_id[i]].arm_vector\",  A[self.A_id[i]].arm_vector)\n",
    "            res = np.outer(np.transpose(double_arm[Id_arm[i]]), double_arm[Id_arm[i]])\n",
    "            #print(\"res\", res)\n",
    "        else:\n",
    "            #print(\"i!=0, print i, res\", i, res)\n",
    "            res += np.outer(np.transpose(double_arm[Id_arm[i]]), double_arm[Id_arm[i]])\n",
    "            #print(\"A\", res)\n",
    "    res += np.diag([1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "    return res\n",
    "\n",
    "def calcola_b():\n",
    "    res = []\n",
    "    global A\n",
    "    for i in range(0, t):\n",
    "        curr = double_arm[Id_arm[i]]\n",
    "        curr = [R[i] * xx for xx in curr]\n",
    "        if i == 0:\n",
    "            res = curr\n",
    "        else:\n",
    "            res = [x + y for x, y in zip(res, curr)]\n",
    "    return res\n",
    "        \n",
    "def stima_theta():\n",
    "    global theta_stimato\n",
    "    if (t == 0):\n",
    "        return theta_stimato\n",
    "    theta_s = np.dot(np.linalg.inv(calcola_A()), calcola_b())\n",
    "    theta_stimato = theta_s\n",
    "    return theta_s\n",
    "\n",
    "\n",
    "def media_reward(index_double_arm):\n",
    "    return np.dot(double_arm[index_double_arm], np.transpose(stima_theta()))\n",
    "    \n",
    "def calcola_bound(index_double_arm):\n",
    "    ris = 2*sigma*math.sqrt(2)*norm_2_mat(double_arm[index_double_arm], np.linalg.inv(calcola_A()))*math.sqrt(math.log(6/(math.pow(math.pi, 2))*math.pow(t, 2)*K/delta))\n",
    "    #print(\"sqrt\", math.sqrt(math.log(6/(math.pow(math.pi, 2))*math.pow(self.times, 2)*K/delta)))\n",
    "    #print(\"bound\", ris)\n",
    "    return ris\n",
    "    \n",
    "def upper_bound(index_double_arm):\n",
    "    return media_reward(index_double_arm) + calcola_bound(index_double_arm)\n",
    "    #return self.media_reward(arm_vector)\n",
    "    \n",
    "def lower_bound(index_double_arm):\n",
    "    return media_reward(index_double_arm) - calcola_bound(index_double_arm)\n",
    "    #return self.media_reward(arm_vector)\n",
    "\n",
    "class arm():\n",
    "    arm_vector = np.array([])\n",
    "    id = 0\n",
    "    worst_y = -1\n",
    "    \n",
    "    def __init__(self, vector):\n",
    "        self.arm_vector = vector\n",
    "        global num_arms, A, N\n",
    "        A.append(self)\n",
    "        self.id = num_arms\n",
    "        num_arms +=1        \n",
    "        \n",
    "    def generate_double(self):\n",
    "        for i in range(0, num_arms_y):\n",
    "            double_arm.append(create_union_arm(self.id, i))\n",
    "\n",
    "    def pull_arm(self, y_index):\n",
    "        reward = np.dot(self.arm_vector, np.dot(M[M_vero].matrix, np.transpose(Y[y_index].arm_vector))) + np.random.normal(0, +sigma)\n",
    "        played_superarm[self.id * num_arms_y + y_index] += 1\n",
    "        R.append(reward)\n",
    "        Id_arm.append(self.id * num_arms_y + y_index)\n",
    "        return reward\n",
    "    \n",
    "    def find_worst_y(self):\n",
    "        #print(\"find worst y\")\n",
    "        mini = 100000000\n",
    "        index = - 1\n",
    "        for i in range(0, num_arms_y):\n",
    "            curr = np.dot(double_arm[self.id * num_arms_y + i], theta_stimato)\n",
    "            if curr < mini:\n",
    "                index = i\n",
    "                mini = curr\n",
    "        self.worst_y = index\n",
    "        #print(\"mini\", mini)\n",
    "        return mini\n",
    "    \n",
    "    \n",
    "        \n",
    "    def norm(self):\n",
    "        return np.linalg.norm(self.arm_vector)\n",
    "    \n",
    "class arm_y():\n",
    "    arm_vector = np.array([])\n",
    "    id = 0\n",
    "\n",
    "    def __init__(self, vector):\n",
    "        self.arm_vector = vector\n",
    "        global num_arms_y, Y\n",
    "        Y.append(self)\n",
    "        self.id = num_arms_y\n",
    "        num_arms_y += 1\n",
    "        \n",
    "def run():\n",
    "    global t\n",
    "    #print(\"TIME\", t)\n",
    "    maxi = - 1000\n",
    "    for i in range(0, num_arms):\n",
    "        A[i].find_worst_y()\n",
    "        curr = media_reward(i * num_arms_y + A[i].worst_y)\n",
    "        #print(\"curr\", curr)\n",
    "        if curr > maxi:\n",
    "            best = i\n",
    "            maxi = curr\n",
    "        #print(\"i term and curr value for best, x\", i, \"y\", A[i].worst_y, curr)\n",
    "    #print(\"best\", best, A[best].worst_y)\n",
    "    maxi = -1000\n",
    "    for i in range(0, num_arms):\n",
    "        if i is not best:\n",
    "            curr = upper_bound(i * num_arms_y + A[i].worst_y)\n",
    "            if curr > maxi:\n",
    "                second_best = i\n",
    "                maxi = curr\n",
    "    #print(\"second best\", second_best, A[second_best].worst_y)\n",
    "    A[best].pull_arm(A[best].worst_y)\n",
    "    A[second_best].pull_arm(A[second_best].worst_y)\n",
    "    global num_second_best_super_arm, num_best_super_arm\n",
    "    num_best_super_arm[best * num_arms_y + A[i].worst_y] +=1\n",
    "    num_second_best_super_arm[second_best * num_arms_y + A[i].worst_y] +=1\n",
    "    t+=1\n",
    "    if (t > 250):\n",
    "        final[best * num_arms_y + A[i].worst_y] +=1\n",
    "    return best * num_arms_y + A[i].worst_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = arm( [0.6539936932649052, 0.49234274001921385, 0.9073937998343392] )\n",
    "b = arm( [0.14679488906671767, 0.7429628522780226, 0.5576982329690424] )\n",
    "c = arm( [0.8930164433455009, 0.8780462992936544, 0.9014394768882377] )\n",
    "d = arm( [0.2539102367562567, 0.6194135715644297, 0.3121193794381716] )\n",
    "m = world( [[0.8730240451816763, 0.21159403045606273, 0.28918565354173686], [0.5189626386885673, 0.4849994006831272, 0.9629953198577507], [0.17670422753928094, 0.2532554211216236, 0.9072025363404456]] )\n",
    "z = arm_y( [0.18050836984570318, 0.6401278349403822, 0.48281685719384904] )\n",
    "k = arm_y( [0.5890871013415527, 0.26856705274431947, 0.17129466008906424] )\n",
    "l = arm_y( [0.549236398976063, 0.4311610694683382, 0.9076721344539929] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 0 y 0 reward 0.6329288594539527\n",
      "x 0 y 1 reward 0.28028403190475715\n",
      "x 0 y 2 reward 0.5739501589249083\n",
      "x 1 y 0 reward 1.930132049218806\n",
      "x 1 y 1 reward 0.8719451902053754\n",
      "x 1 y 2 reward 1.7759035558203364\n",
      "x 2 y 0 reward 0.7813755021007334\n",
      "x 2 y 1 reward 0.3016634060141854\n",
      "x 2 y 2 reward 0.7333238007283127\n",
      "x 3 y 0 reward 1.8584720223370566\n",
      "x 3 y 1 reward 0.814040901651403\n",
      "x 3 y 2 reward 1.7293277548503294\n",
      "4\n",
      "0.8719451902053754\n"
     ]
    }
   ],
   "source": [
    "best_super = -1\n",
    "best_value = 0\n",
    "\n",
    "for i in range(0, num_arms):\n",
    "    for j in range (0, num_arms_y):\n",
    "        print(\"x\", i, \"y\", j, \"reward\", np.dot(A[i].arm_vector, np.dot(M[M_vero].matrix, np.transpose(Y[j].arm_vector))))\n",
    "        \n",
    "for i in range(0, num_arms):\n",
    "    min = 10000\n",
    "    val_j = 0\n",
    "    for j in range(0, num_arms_y):\n",
    "        curr = np.dot(A[i].arm_vector, np.dot(M[M_vero].matrix, np.transpose(Y[j].arm_vector)))\n",
    "        if curr < min:\n",
    "            min = curr\n",
    "            val_j = j\n",
    "    if min > best_value:\n",
    "        best_value = min\n",
    "        best_super = i*(j+1)+val_j\n",
    "print(best_super)\n",
    "print(best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17774808504992687,\n",
       " 0.30864476343648256,\n",
       " 0.36964538166614797,\n",
       " 0.02118589161378007,\n",
       " 0.03678753840576917,\n",
       " 0.04405823550399256,\n",
       " 0.10365613322688376,\n",
       " 0.17999025255076986,\n",
       " 0.21556356524418316]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_union_arm(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_all_union()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.17774808504992687,\n",
       "  0.30864476343648256,\n",
       "  0.36964538166614797,\n",
       "  0.02118589161378007,\n",
       "  0.03678753840576917,\n",
       "  0.04405823550399256,\n",
       "  0.10365613322688376,\n",
       "  0.17999025255076986,\n",
       "  0.21556356524418316],\n",
       " [0.30013823235610865,\n",
       "  0.19942066560027874,\n",
       "  0.021176070629647662,\n",
       "  0.035773640307078365,\n",
       "  0.023769058360143067,\n",
       "  0.002523987456964457,\n",
       "  0.1750295570883226,\n",
       "  0.11629478357446212,\n",
       "  0.012349104058094952],\n",
       " [0.20791328825077476,\n",
       "  0.2025181769174174,\n",
       "  0.3649537583298306,\n",
       "  0.024781298705458768,\n",
       "  0.0241382524306104,\n",
       "  0.04349903834882782,\n",
       "  0.12124736815312692,\n",
       "  0.11810113803206945,\n",
       "  0.21282758339963578],\n",
       " [0.3934191565191531,\n",
       "  0.6831396381070857,\n",
       "  0.8181555048846147,\n",
       "  0.1598303386055703,\n",
       "  0.2775320872516452,\n",
       "  0.3323835893877046,\n",
       "  0.30474603152907287,\n",
       "  0.5291661329745293,\n",
       "  0.633750642681562],\n",
       " [0.6643116868433371,\n",
       "  0.4413882154112244,\n",
       "  0.04687010745103621,\n",
       "  0.2698830498932226,\n",
       "  0.17931823287372103,\n",
       "  0.019041434613044517,\n",
       "  0.5145818318941857,\n",
       "  0.3419032977458018,\n",
       "  0.03630600850609353],\n",
       " [0.4601853824178626,\n",
       "  0.44824409962148143,\n",
       "  0.8077712889581192,\n",
       "  0.1869547638298596,\n",
       "  0.18210350216376034,\n",
       "  0.32816490120187825,\n",
       "  0.35646375306258127,\n",
       "  0.34721392756917935,\n",
       "  0.6257069352471315],\n",
       " [0.0030500888347614833,\n",
       "  0.005296225535148752,\n",
       "  0.006342972702768529,\n",
       "  0.07111915766571049,\n",
       "  0.12349250112804043,\n",
       "  0.14789958593214853,\n",
       "  0.24365463360926135,\n",
       "  0.4230860024703498,\n",
       "  0.5067048120936024],\n",
       " [0.005150256730683082,\n",
       "  0.0034219819887075847,\n",
       "  0.00036337323450470266,\n",
       "  0.12008893520538394,\n",
       "  0.07979061914868707,\n",
       "  0.008472801861280885,\n",
       "  0.4114253665029236,\n",
       "  0.27336310935390823,\n",
       "  0.02902786676492954],\n",
       " [0.003567712129861255,\n",
       "  0.0034751340926039397,\n",
       "  0.006262466249205395,\n",
       "  0.08318862014040723,\n",
       "  0.08102997087319667,\n",
       "  0.14602241071718094,\n",
       "  0.28500467983669064,\n",
       "  0.27760913532299797,\n",
       "  0.500273599263816],\n",
       " [0.22055415222809044,\n",
       "  0.38297393820165343,\n",
       "  0.4586649907114694,\n",
       "  0.19610694886419303,\n",
       "  0.340523403239129,\n",
       "  0.40782452277855474,\n",
       "  0.36487883136586036,\n",
       "  0.6335817376500199,\n",
       "  0.7588029701937258],\n",
       " [0.3724188272967636,\n",
       "  0.24744601791843096,\n",
       "  0.0262757840903447,\n",
       "  0.3311382677811465,\n",
       "  0.22001800053346507,\n",
       "  0.023363259294446968,\n",
       "  0.6161196473061922,\n",
       "  0.4093680075033904,\n",
       "  0.043469947381410266],\n",
       " [0.2579838709048477,\n",
       "  0.25128948538744217,\n",
       "  0.4528435102312474,\n",
       "  0.22938779101742954,\n",
       "  0.22343544097061938,\n",
       "  0.4026483210915054,\n",
       "  0.42680154681310406,\n",
       "  0.4157265362561622,\n",
       "  0.7491720701495233]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,num_arms):\n",
    "    for j in range (0, num_arms_y):\n",
    "        A[i].pull_arm(j)\n",
    "        t+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7432327119719722,\n",
       " 0.2074943852033741,\n",
       " 0.5515697213876013,\n",
       " 2.1227505926231487,\n",
       " 0.9043724842466027,\n",
       " 1.7988761848011086,\n",
       " 0.864560906490626,\n",
       " 0.21792529688791917,\n",
       " 0.7939331375819665,\n",
       " 1.8531725188165358,\n",
       " 0.7709037997125958,\n",
       " 1.8304046256190805]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Id_arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2836426 , 0.39447971, 0.54181964, 0.18179071, 0.24344387,\n",
       "       0.35309955, 0.33639492, 0.47613865, 0.71547203])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stima_theta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,num_arms):\n",
    "    A[i].find_worst_y()\n",
    "    print(A[i].worst_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 lower_bound 0.45876566835901755 mean 0.6756156084613776 upper 0.8924655485637376\n",
      "index 1 lower_bound 0.1106449683158639 mean 0.31154090609208107 upper 0.5124368438682982\n",
      "index 2 lower_bound 0.4128401544399873 mean 0.6116339989742756 upper 0.8104278435085639\n",
      "index 3 lower_bound 1.401804524048983 mean 1.8462538543745675 upper 2.290703184700152\n",
      "index 4 lower_bound 0.3910350907031228 mean 0.8492526372988765 upper 1.30747018389463\n",
      "index 5 lower_bound 1.2623841901075976 mean 1.6721216058996156 upper 2.0818590216916335\n",
      "index 6 lower_bound 0.4210139468640422 mean 0.7475516092896957 upper 1.0740892717153492\n",
      "index 7 lower_bound 0.05625177261138581 mean 0.3365837243149762 upper 0.6169156760185666\n",
      "index 8 lower_bound 0.3798983169962396 mean 0.6781719025227766 upper 0.9764454880493136\n",
      "index 9 lower_bound 1.2972809261210176 mean 1.692017554679115 upper 2.0867541832372125\n",
      "index 10 lower_bound 0.363644333358068 mean 0.7727694499827682 upper 1.1818945666074683\n",
      "index 11 lower_bound 1.1694277596090925 mean 1.5334618327353837 upper 1.897495905861675\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,num_double_arm):\n",
    "    print(\"index\", i, \"lower_bound\", lower_bound(i), \"mean\", media_reward(i), \"upper\", upper_bound(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 lower_bound 0.4565278817726973 mean 0.6741026963625084 upper 0.8916775109523195\n",
      "index 1 lower_bound 0.12453015897385528 mean 0.3057452803358679 upper 0.4869604016978805\n",
      "index 2 lower_bound 0.41074592908969615 mean 0.6103105837603655 upper 0.8098752384310348\n",
      "index 3 lower_bound 1.3972511501511788 mean 1.843107384128446 upper 2.288963618105713\n",
      "index 4 lower_bound 0.4303526388128597 mean 0.8349829396824148 upper 1.2396132405519698\n",
      "index 5 lower_bound 1.2580704717626383 mean 1.6693895992373955 upper 2.0807087267121527\n",
      "index 6 lower_bound 0.41872274853686786 mean 0.7481593189080997 upper 1.0775958892793316\n",
      "index 7 lower_bound 0.05438913902067849 mean 0.3337099245148968 upper 0.613030710009115\n",
      "index 8 lower_bound 0.37784099146001726 mean 0.6787512899248561 upper 0.979661588389695\n",
      "index 9 lower_bound 1.292842369865605 mean 1.6907645899424248 upper 2.0886868100192446\n",
      "index 10 lower_bound 0.3838942273132074 mean 0.7622278263823367 upper 1.140561425451466\n",
      "index 11 lower_bound 1.1653638475244366 mean 1.5324185569060196 upper 1.8994732662876026\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,num_double_arm):\n",
    "    print(\"index\", i, \"lower_bound\", lower_bound(i), \"mean\", media_reward(i), \"upper\", upper_bound(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7432327119719722,\n",
       " 0.2074943852033741,\n",
       " 0.5515697213876013,\n",
       " 2.1227505926231487,\n",
       " 0.9043724842466027,\n",
       " 1.7988761848011086,\n",
       " 0.864560906490626,\n",
       " 0.21792529688791917,\n",
       " 0.7939331375819665,\n",
       " 1.8531725188165358,\n",
       " 0.7709037997125958,\n",
       " 1.8304046256190805,\n",
       " 0.788406896205466,\n",
       " 0.743239441548773]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, 800):\n",
    "    bst = run()\n",
    "    if num_best_super_arm.index(max(num_best_super_arm)) == best_super:\n",
    "        sample_correct[i] += 1\n",
    "    error_reward[i] += best_value - media_reward(best_super)\n",
    "    error_best_choosen[i] += best_value - media_reward(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 801, 0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_second_best_super_arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 801, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_best_super_arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 lower_bound 0.38713943762851116 mean 0.6699988064342659 upper 0.9528581752400207\n",
      "index 1 lower_bound 0.23567053134956484 mean 0.3113441074556477 upper 0.3870176835617306\n",
      "index 2 lower_bound 0.34610554494572343 mean 0.6065245431582569 upper 0.8669435413707903\n",
      "index 3 lower_bound 1.23958236474517 mean 1.8423107871476432 upper 2.4450392095501163\n",
      "index 4 lower_bound 0.8067000702513393 mean 0.8642120493392232 upper 0.9217240284271072\n",
      "index 5 lower_bound 1.1108502802502673 mean 1.6683961996078036 upper 2.2259421189653397\n",
      "index 6 lower_bound 0.34535053398891574 mean 0.7617880535733261 upper 1.1782255731577365\n",
      "index 7 lower_bound 0.22018665162189038 mean 0.3658492593479327 upper 0.5115118670739751\n",
      "index 8 lower_bound 0.30878049473806046 mean 0.6908571536829089 upper 1.0729338126277574\n",
      "index 9 lower_bound 1.1666177072958739 mean 1.7035078905069563 upper 2.2403980737180387\n",
      "index 10 lower_bound 0.7506743638277344 mean 0.8080725726946383 upper 0.8654707815615421\n",
      "index 11 lower_bound 1.046842684469553 mean 1.5435932532993457 upper 2.040343822129138\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,num_double_arm):\n",
    "    print(\"index\", i, \"lower_bound\", lower_bound(i), \"mean\", media_reward(i), \"upper\", upper_bound(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 0 y 0 reward 0.6329288594539527\n",
      "x 0 y 1 reward 0.28028403190475715\n",
      "x 0 y 2 reward 0.5739501589249083\n",
      "x 1 y 0 reward 1.930132049218806\n",
      "x 1 y 1 reward 0.8719451902053754\n",
      "x 1 y 2 reward 1.7759035558203364\n",
      "x 2 y 0 reward 0.7813755021007334\n",
      "x 2 y 1 reward 0.3016634060141854\n",
      "x 2 y 2 reward 0.7333238007283127\n",
      "x 3 y 0 reward 1.8584720223370566\n",
      "x 3 y 1 reward 0.814040901651403\n",
      "x 3 y 2 reward 1.7293277548503294\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, num_arms):\n",
    "    for j in range (0, num_arms_y):\n",
    "        print(\"x\", i, \"y\", j, \"reward\", np.dot(A[i].arm_vector, np.dot(M[M_vero].matrix, np.transpose(Y[j].arm_vector))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 563, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\effel\\\\Desktop\\\\LinearBanditExp'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.039692280733775176,\n",
       " 0.0420773376320176,\n",
       " 0.05701578588024048,\n",
       " 0.07767787132558024,\n",
       " 0.08191688335441805,\n",
       " 0.05847734039656871,\n",
       " 0.03389514666771842,\n",
       " 0.040308261968697745,\n",
       " 0.026902145802442545,\n",
       " 0.01612895961651284,\n",
       " 0.01814549738891147,\n",
       " 0.018683159708375308,\n",
       " 0.019861104293474208,\n",
       " 0.014991425957523896,\n",
       " 0.013362938460523388,\n",
       " 0.016013299134618686,\n",
       " 0.01478842518054091,\n",
       " 0.014500603418594049,\n",
       " 0.010897958859287682,\n",
       " 0.007415562899895423,\n",
       " 0.013009172576869288,\n",
       " 0.016731947776007505,\n",
       " 0.013598381817993,\n",
       " 0.02086462750112794,\n",
       " 0.018176837810415902,\n",
       " 0.011813445537171119,\n",
       " 0.010914712394337167,\n",
       " 0.016320311842734747,\n",
       " 0.014940877569583177,\n",
       " 0.017318550986299308,\n",
       " 0.01668340132588897,\n",
       " 0.017806619292503267,\n",
       " 0.016511171335924724,\n",
       " 0.016092169466564665,\n",
       " 0.0161540268013336,\n",
       " 0.014431580730788873,\n",
       " 0.012768588615439058,\n",
       " 0.011631103242207286,\n",
       " 0.013971864921887178,\n",
       " 0.018648554091138192,\n",
       " 0.018789833665729283,\n",
       " 0.020078027363003903,\n",
       " 0.020352798063446365,\n",
       " 0.01857382859058876,\n",
       " 0.01863707688623184,\n",
       " 0.016205403817300734,\n",
       " 0.015926350094289443,\n",
       " 0.01686556207928469,\n",
       " 0.017032845074914316,\n",
       " 0.017783631876270523,\n",
       " 0.017963585060777887,\n",
       " 0.018294537920598097,\n",
       " 0.019099183165867006,\n",
       " 0.019090586003261967,\n",
       " 0.019230315938178144,\n",
       " 0.016937824487349373,\n",
       " 0.017039899454132312,\n",
       " 0.012491193328057038,\n",
       " 0.013145287638969383,\n",
       " 0.014303700694184074,\n",
       " 0.014471403613756761,\n",
       " 0.014132061269514495,\n",
       " 0.014809641791030836,\n",
       " 0.010722718766261297,\n",
       " 0.01130534246305015,\n",
       " 0.010042254917205895,\n",
       " 0.009867509355518167,\n",
       " 0.006040826935196586,\n",
       " 0.006108474548470966,\n",
       " 0.0009273056882153075,\n",
       " 0.0011780096855272815,\n",
       " 0.0003461146589198716,\n",
       " 0.0006688392779320429,\n",
       " 0.0025164036469297324,\n",
       " 0.0028175635085943007,\n",
       " 0.005515519822421711,\n",
       " 0.005143645187040469,\n",
       " 0.007156567832266925,\n",
       " 0.007176263269351724,\n",
       " 0.006262133022798766,\n",
       " 0.006214314065309368,\n",
       " 0.005451555492249405,\n",
       " 0.00521763998597824,\n",
       " 0.005275694984631318,\n",
       " 0.0054312986168933985,\n",
       " 0.004878551678816456,\n",
       " 0.004557535023977599,\n",
       " 0.003838175769683483,\n",
       " 0.003835165646216221,\n",
       " 0.004731466772161408,\n",
       " 0.0052159853695539216,\n",
       " 0.00474155906694862,\n",
       " 0.005409820592537584,\n",
       " 0.005263592386815619,\n",
       " 0.0051642736182788695,\n",
       " 0.00488762185353242,\n",
       " 0.004484873068865913,\n",
       " 0.00338558773982367,\n",
       " 0.003720496011591745,\n",
       " 0.0035712762458137703,\n",
       " 0.003705049287527462,\n",
       " 0.0061038825339909675,\n",
       " 0.005901305223527276,\n",
       " 0.005367945162790599,\n",
       " 0.0052187867604274185,\n",
       " 0.005259974132623579,\n",
       " 0.005741792183926675,\n",
       " 0.006806695631922155,\n",
       " 0.0070632073110082905,\n",
       " 0.0050352277459051464,\n",
       " 0.005088923309517934,\n",
       " 0.002214280432490612,\n",
       " 0.0020008355479546047,\n",
       " 0.00019358540083502795,\n",
       " 0.00044959861095672515,\n",
       " -0.00034367590411421567,\n",
       " -0.00023789412883967742,\n",
       " 0.0007590339715849437,\n",
       " 0.0009620144439795864,\n",
       " 0.0019302828041959375,\n",
       " 0.0016583285924650637,\n",
       " 0.004236969749995323,\n",
       " 0.004562368457927568,\n",
       " 0.0029627570400840852,\n",
       " 0.002844722143919065,\n",
       " 0.0026167286386196142,\n",
       " 0.0025419474492940353,\n",
       " 0.0030311082641498732,\n",
       " 0.0027803429512132105,\n",
       " 0.004503343542319738,\n",
       " 0.004486267060538451,\n",
       " 0.003647651736483737,\n",
       " 0.003480843487136509,\n",
       " 0.0038023463617146147,\n",
       " 0.0038017177424043425,\n",
       " 0.004352787577496242,\n",
       " 0.004335849406023273,\n",
       " 0.005390090659888269,\n",
       " 0.005267122501552812,\n",
       " 0.005452801691636644,\n",
       " 0.005146520739117144,\n",
       " 0.004133455786186402,\n",
       " 0.003719746784453193,\n",
       " 0.002465712558133548,\n",
       " 0.002635987581605548,\n",
       " 0.002678707984500761,\n",
       " 0.002706116834098826,\n",
       " 0.002885823653565267,\n",
       " 0.002882980691396364,\n",
       " 0.0017839647359746413,\n",
       " 0.0017623490568061673,\n",
       " 0.0035942353071949373,\n",
       " 0.003723262909200109,\n",
       " 0.003073101666779654,\n",
       " 0.002903595281141258,\n",
       " 0.0017646691119790336,\n",
       " 0.0019617647835504792,\n",
       " 0.0025308192775486127,\n",
       " 0.0023897699840593756,\n",
       " 0.0014123591138931468,\n",
       " 0.0013640301336663718,\n",
       " 0.0013222615650141378,\n",
       " 0.0013496012562588255,\n",
       " 0.002150515121036145,\n",
       " 0.0019839141097053314,\n",
       " 0.004220738289063997,\n",
       " 0.004135001731523924,\n",
       " 0.0036334024229200956,\n",
       " 0.0035438011622330734,\n",
       " 0.00258509664828499,\n",
       " 0.0025553035054658446,\n",
       " 0.0041245999777219655,\n",
       " 0.0040284180202974085,\n",
       " 0.004641626972087032,\n",
       " 0.004555795007620267,\n",
       " 0.0031731230664522325,\n",
       " 0.003231114112182465,\n",
       " 0.0035753036973624752,\n",
       " 0.003438363279094969,\n",
       " 0.003997476620162255,\n",
       " 0.004038634728523283,\n",
       " 0.005888546591223731,\n",
       " 0.00596803050921757,\n",
       " 0.006708817358300312,\n",
       " 0.006687636244276929,\n",
       " 0.006068677649548104,\n",
       " 0.0060749389301888446,\n",
       " 0.00748114586360793,\n",
       " 0.007300327931649142,\n",
       " 0.007930851176781717,\n",
       " 0.007937450395880563,\n",
       " 0.007607486909778305,\n",
       " 0.007600068705593821,\n",
       " 0.0070213767075291145,\n",
       " 0.007035329456717809,\n",
       " 0.005998708425281829,\n",
       " 0.0060423276876353516,\n",
       " 0.007014302465101707,\n",
       " 0.0070161544569921075,\n",
       " 0.009844267622754588,\n",
       " 0.009818982429999012,\n",
       " 0.009779256803787328,\n",
       " 0.009844397758196677,\n",
       " 0.00921046139515247,\n",
       " 0.009335721662615537,\n",
       " 0.007898465439634239,\n",
       " 0.007817619055426661,\n",
       " 0.008043375976334644,\n",
       " 0.008036420844904635,\n",
       " 0.008463763406037828,\n",
       " 0.008422218561146111,\n",
       " 0.007834179416347231,\n",
       " 0.007859901406703784,\n",
       " 0.007202634557188281,\n",
       " 0.007194431945445001,\n",
       " 0.006958102575632785,\n",
       " 0.006980571014541637,\n",
       " 0.007831884985054716,\n",
       " 0.00788476247351555,\n",
       " 0.008449478077894979,\n",
       " 0.008396520541461783,\n",
       " 0.008547031505135472,\n",
       " 0.00856550389488342,\n",
       " 0.01037240444115528,\n",
       " 0.010516351323202056,\n",
       " 0.011048158542220854,\n",
       " 0.011122672855556459,\n",
       " 0.010959323954660483,\n",
       " 0.01095577134152026,\n",
       " 0.011549182501914057,\n",
       " 0.011507111154040572,\n",
       " 0.01150670466064807,\n",
       " 0.011367585423547766,\n",
       " 0.011057873923424388,\n",
       " 0.011179109783728602,\n",
       " 0.010905939609575643,\n",
       " 0.010899736332971699,\n",
       " 0.010741933313455077,\n",
       " 0.010684218776235932,\n",
       " 0.010554693554746364,\n",
       " 0.010526957855645502,\n",
       " 0.011099361905372973,\n",
       " 0.011025534796238468,\n",
       " 0.010639289595058221,\n",
       " 0.010610233481440634,\n",
       " 0.010863283399109691,\n",
       " 0.010819288727129672,\n",
       " 0.01177779110221433,\n",
       " 0.011832899707924227,\n",
       " 0.012744219970029613,\n",
       " 0.012769800093362038,\n",
       " 0.014265303760958914,\n",
       " 0.014281744733319224,\n",
       " 0.01428842353947446,\n",
       " 0.014219343820944585,\n",
       " 0.014978845651044237,\n",
       " 0.014996307339698811,\n",
       " 0.015813234688026423,\n",
       " 0.015806117832253608,\n",
       " 0.015387094585327832,\n",
       " 0.01542125001281247,\n",
       " 0.014666022070253137,\n",
       " 0.014654080226879418,\n",
       " 0.014033043307566828,\n",
       " 0.014018323639534369,\n",
       " 0.014310565092733318,\n",
       " 0.014377437998959519,\n",
       " 0.014566766931285113,\n",
       " 0.014459143676602726,\n",
       " 0.01454759811128481,\n",
       " 0.014512090514680498,\n",
       " 0.014596479445002863,\n",
       " 0.014600488396403932,\n",
       " 0.014159402774488017,\n",
       " 0.014124527576886758,\n",
       " 0.013994505682461744,\n",
       " 0.014017496997128953,\n",
       " 0.013809500351373516,\n",
       " 0.013846761100267058,\n",
       " 0.013909428311970284,\n",
       " 0.013930516420273764,\n",
       " 0.013806692998721504,\n",
       " 0.013797187566771507,\n",
       " 0.014051962908851912,\n",
       " 0.01403671222524383,\n",
       " 0.013774465446731221,\n",
       " 0.013791859533430761,\n",
       " 0.013043865435205193,\n",
       " 0.013016020939562223,\n",
       " 0.013971337995904776,\n",
       " 0.013927760875140138,\n",
       " 0.014448055100857782,\n",
       " 0.014429830195897941,\n",
       " 0.013361889763594537,\n",
       " 0.01337267302008116,\n",
       " 0.01495350755521696,\n",
       " 0.014930902363865739,\n",
       " 0.013999254197480493,\n",
       " 0.01404860284387488,\n",
       " 0.014808888351576455,\n",
       " 0.014809567459723616,\n",
       " 0.014675136628904628,\n",
       " 0.014739684056200963,\n",
       " 0.013757976946157102,\n",
       " 0.01377766896641286,\n",
       " 0.0141680129499544,\n",
       " 0.014198184106132161,\n",
       " 0.013875801893890483,\n",
       " 0.013831197797490091,\n",
       " 0.013783672729167029,\n",
       " 0.013772975269524479,\n",
       " 0.013787096053639925,\n",
       " 0.013787160102440854,\n",
       " 0.01352632375529983,\n",
       " 0.013522757765645155,\n",
       " 0.014265116081970675,\n",
       " 0.014291353953600816,\n",
       " 0.014085286506578698,\n",
       " 0.014107194810909607,\n",
       " 0.013640820628897266,\n",
       " 0.013636842780121894,\n",
       " 0.013145171457775717,\n",
       " 0.01313395727826383,\n",
       " 0.01274088902775583,\n",
       " 0.012713476304948568,\n",
       " 0.012363207674961685,\n",
       " 0.012346280733435133,\n",
       " 0.013253584173515298,\n",
       " 0.013270766169974135,\n",
       " 0.01311241944296171,\n",
       " 0.013105921614178229,\n",
       " 0.013286469590309657,\n",
       " 0.013258594671604174,\n",
       " 0.013882582972790103,\n",
       " 0.013874743077416984,\n",
       " 0.014323992697078736,\n",
       " 0.01424875860139907,\n",
       " 0.013863369978757811,\n",
       " 0.013851738776627931,\n",
       " 0.012804878179947798,\n",
       " 0.012810075151593714,\n",
       " 0.013498074543353944,\n",
       " 0.01349012390380755,\n",
       " 0.01413445284455117,\n",
       " 0.014142775940269692,\n",
       " 0.013906314302169598,\n",
       " 0.013935628794899513,\n",
       " 0.012807072156221011,\n",
       " 0.012804240750893037,\n",
       " 0.012125633954685022,\n",
       " 0.012135163738800081,\n",
       " 0.012321409759037283,\n",
       " 0.012320457781432204,\n",
       " 0.011725409983437851,\n",
       " 0.011720125477564514,\n",
       " 0.011334857378336505,\n",
       " 0.011341066812743383,\n",
       " 0.010630420548035424,\n",
       " 0.01062781770535004,\n",
       " 0.010657435498562906,\n",
       " 0.010618176368493604,\n",
       " 0.010247805762047757,\n",
       " 0.010256132746628621,\n",
       " 0.009248467054619236,\n",
       " 0.009234348378669321,\n",
       " 0.009736192678502231,\n",
       " 0.009775691629113514,\n",
       " 0.009706161463747365,\n",
       " 0.009688144520447306,\n",
       " 0.010019780884465979,\n",
       " 0.010011913547318896,\n",
       " 0.010561846296844646,\n",
       " 0.010564111526375819,\n",
       " 0.010343455826487324,\n",
       " 0.010330190203641232,\n",
       " 0.011077412968323874,\n",
       " 0.011077078404662544,\n",
       " 0.010826294104056444,\n",
       " 0.010823310272615183,\n",
       " 0.010139659812752444,\n",
       " 0.010127276857899048,\n",
       " 0.010558240559958021,\n",
       " 0.010544461767289515,\n",
       " 0.011038083461410886,\n",
       " 0.011042169346836661,\n",
       " 0.011147635345973184,\n",
       " 0.011159070446547403,\n",
       " 0.010526477119019662,\n",
       " 0.010505164310258497,\n",
       " 0.010883735504084946,\n",
       " 0.01091017492766766,\n",
       " 0.011765855938507541,\n",
       " 0.011765993669568875,\n",
       " 0.012517519292688517,\n",
       " 0.012504215304761312,\n",
       " 0.012923049656714536,\n",
       " 0.012923009447391776,\n",
       " 0.01265786808901137,\n",
       " 0.012688506959052437,\n",
       " 0.012691583003659912,\n",
       " 0.012670845252564344,\n",
       " 0.012092730787736872,\n",
       " 0.012121319627934946,\n",
       " 0.012052044663362738,\n",
       " 0.012031509839414811,\n",
       " 0.011263596039012391,\n",
       " 0.011247486712106403,\n",
       " 0.010729589581887411,\n",
       " 0.010711097292199545,\n",
       " 0.01062323175646751,\n",
       " 0.010637727656268137,\n",
       " 0.010891203731683063,\n",
       " 0.010869969427712567,\n",
       " 0.00990906610030129,\n",
       " 0.009874775832829363,\n",
       " 0.009310306782700617,\n",
       " 0.009349052003332359,\n",
       " 0.009756095063938153,\n",
       " 0.009745604796118745,\n",
       " 0.00935348678023451,\n",
       " 0.00932370629645296,\n",
       " 0.009412492279998075,\n",
       " 0.009391811002498085,\n",
       " 0.00957707483866832,\n",
       " 0.009607613462033093,\n",
       " 0.010053179669478274,\n",
       " 0.010055264034055433,\n",
       " 0.010098081020109562,\n",
       " 0.010110037938358074,\n",
       " 0.010098083885565323,\n",
       " 0.010097139147473122,\n",
       " 0.009811543856192206,\n",
       " 0.00981439507575843,\n",
       " 0.009720228507983486,\n",
       " 0.00973106271264279,\n",
       " 0.009437613649899368,\n",
       " 0.009422932286633934,\n",
       " 0.009754559023557596,\n",
       " 0.009735846122436609,\n",
       " 0.010148694339593867,\n",
       " 0.0101465971781034,\n",
       " 0.009783967658358761,\n",
       " 0.009801984530372065,\n",
       " 0.009386829948611619,\n",
       " 0.009385499067285807,\n",
       " 0.009285799335171818,\n",
       " 0.009282784443083725,\n",
       " 0.009412223879228798,\n",
       " 0.009416586532887017,\n",
       " 0.009013195577845856,\n",
       " 0.009039933753044127,\n",
       " 0.008703203584823571,\n",
       " 0.008703333935134672,\n",
       " 0.008703751086168388,\n",
       " 0.008682548622958142,\n",
       " 0.009825028817578518,\n",
       " 0.009837049055963054,\n",
       " 0.009768282889260904,\n",
       " 0.009740157028827579,\n",
       " 0.009669985663194214,\n",
       " 0.009682307585321182,\n",
       " 0.009943444385463795,\n",
       " 0.009951983108876572,\n",
       " 0.010050488226935883,\n",
       " 0.010054975308654734,\n",
       " 0.010618246063761716,\n",
       " 0.010624794976336505,\n",
       " 0.010229830978549126,\n",
       " 0.01024621450028751,\n",
       " 0.011115583143755048,\n",
       " 0.011131910952423163,\n",
       " 0.011714210189470275,\n",
       " 0.01169024658903528,\n",
       " 0.011649897376040053,\n",
       " 0.011634829296115368,\n",
       " 0.011632410082058953,\n",
       " 0.01162730716933802,\n",
       " 0.012197152127565225,\n",
       " 0.012216729838699703,\n",
       " 0.012274642757875709,\n",
       " 0.012259749377668605,\n",
       " 0.012279452847445915,\n",
       " 0.012289741857142489,\n",
       " 0.011895564968226968,\n",
       " 0.011893348126986059,\n",
       " 0.012653176681816314,\n",
       " 0.012639170779311981,\n",
       " 0.01229915129352277,\n",
       " 0.012289391542587458,\n",
       " 0.012156754193316521,\n",
       " 0.01214555289146424,\n",
       " 0.012105758430361657,\n",
       " 0.012090003525303539,\n",
       " 0.012540999313889856,\n",
       " 0.012519688885217484,\n",
       " 0.01259262572085762,\n",
       " 0.012596297510484522,\n",
       " 0.012764078357580533,\n",
       " 0.012760772186517277,\n",
       " 0.012920827731536688,\n",
       " 0.012927245239679919,\n",
       " 0.013457657525185462,\n",
       " 0.013455866270401295,\n",
       " 0.013332161000840115,\n",
       " 0.013338063781899612,\n",
       " 0.012994707856969767,\n",
       " 0.013006904817908005,\n",
       " 0.012862292650652307,\n",
       " 0.012861640833424115,\n",
       " 0.012542561212538161,\n",
       " 0.012550368246528887,\n",
       " 0.012936169207019566,\n",
       " 0.01293728816765638,\n",
       " 0.01303593863845487,\n",
       " 0.013035474404059277,\n",
       " 0.013501956914455104,\n",
       " 0.013517592568509373,\n",
       " 0.013216380154859264,\n",
       " 0.013194020217652147,\n",
       " 0.01278046520049858,\n",
       " 0.012767952145941064,\n",
       " 0.013706354965846268,\n",
       " 0.01370628436368948,\n",
       " 0.014099620826134585,\n",
       " 0.01409469899885063,\n",
       " 0.0139323778286774,\n",
       " 0.013932038227338683,\n",
       " 0.01364262719684306,\n",
       " 0.013651419472272441,\n",
       " 0.012617620041248001,\n",
       " 0.012613888373014692,\n",
       " 0.0124899240274996,\n",
       " 0.012474153960615686,\n",
       " 0.012495027437275152,\n",
       " 0.012511288172005752,\n",
       " 0.012292120926447714,\n",
       " 0.01228182210453499,\n",
       " 0.012323878587284343,\n",
       " 0.012328664278843382,\n",
       " 0.012132528727376801,\n",
       " 0.012126022658136781,\n",
       " 0.012188267497393213,\n",
       " 0.012198091607240724,\n",
       " 0.012332230263619404,\n",
       " 0.012348123879361794,\n",
       " 0.011966461186845967,\n",
       " 0.011980995775279668,\n",
       " 0.01184312003267829,\n",
       " 0.011839948812595757,\n",
       " 0.011316212639700063,\n",
       " 0.011316997868027867,\n",
       " 0.011293577577052738,\n",
       " 0.01128306383157962,\n",
       " 0.010736479855941616,\n",
       " 0.010739736749750373,\n",
       " 0.010457959209947187,\n",
       " 0.010452234837440955,\n",
       " 0.010030479644535184,\n",
       " 0.01005137821203328,\n",
       " 0.010566088392443884,\n",
       " 0.010564220272327729,\n",
       " 0.01078969853216849,\n",
       " 0.010791903739909459,\n",
       " 0.010601506377458048,\n",
       " 0.0106189407048225,\n",
       " 0.011044257018155701,\n",
       " 0.01102765378861259,\n",
       " 0.010892870325467485,\n",
       " 0.01089454313666427,\n",
       " 0.010921379002744147,\n",
       " 0.010917468124075569,\n",
       " 0.011590143388880314,\n",
       " 0.011581283994372416,\n",
       " 0.011725578982297757,\n",
       " 0.011754226274934387,\n",
       " 0.012085964524034654,\n",
       " 0.012083311106917405,\n",
       " 0.011533596782220323,\n",
       " 0.01151417701343993,\n",
       " 0.011288911555229597,\n",
       " 0.01128233011432711,\n",
       " 0.011521407833838926,\n",
       " 0.011517454699388363,\n",
       " 0.011617736793608335,\n",
       " 0.011612625136221855,\n",
       " 0.012087366932242105,\n",
       " 0.012091839209347421,\n",
       " 0.011829660526626706,\n",
       " 0.011831779975510992,\n",
       " 0.01202992030044614,\n",
       " 0.01204887794913767,\n",
       " 0.011523039558900772,\n",
       " 0.01153031004020899,\n",
       " 0.011089638185863171,\n",
       " 0.011092203862943073,\n",
       " 0.011270839071235828,\n",
       " 0.011253830661031472,\n",
       " 0.011229894030452159,\n",
       " 0.011229734715244577,\n",
       " 0.011410541654222728,\n",
       " 0.011432715941061544,\n",
       " 0.011793448876814994,\n",
       " 0.011822005492899246,\n",
       " 0.012329048389721375,\n",
       " 0.012339863812977026,\n",
       " 0.012745099189969467,\n",
       " 0.012748556122262222,\n",
       " 0.012556431215123953,\n",
       " 0.012559915484002149,\n",
       " 0.012431640963648793,\n",
       " 0.012414360874796193,\n",
       " 0.012754413232559325,\n",
       " 0.012756742837348733,\n",
       " 0.012578455303372538,\n",
       " 0.012567003948075417,\n",
       " 0.012583511769308608,\n",
       " 0.012586467067225993,\n",
       " 0.012030468053518262,\n",
       " 0.012016180185816516,\n",
       " 0.011890769687714409,\n",
       " 0.01190469201415989,\n",
       " 0.012002990992629248,\n",
       " 0.011992549300875455,\n",
       " 0.011682039047192116,\n",
       " 0.01167527707541538,\n",
       " 0.011645118780956976,\n",
       " 0.011643918244959028,\n",
       " 0.011512088846533208,\n",
       " 0.011518520355566109,\n",
       " 0.011149511144397328,\n",
       " 0.011156883410435747,\n",
       " 0.011153189265591723,\n",
       " 0.011144015757480585,\n",
       " 0.011012594101426298,\n",
       " 0.011017144654508648,\n",
       " 0.01107727925050983,\n",
       " 0.011080575114630786,\n",
       " 0.011256223498839035,\n",
       " 0.011236781638473636,\n",
       " 0.010953804205426576,\n",
       " 0.010955151369762994,\n",
       " 0.01109965561106585,\n",
       " 0.011100918347902056,\n",
       " 0.011032481629508095,\n",
       " 0.0110277454964397,\n",
       " 0.011124967756557469,\n",
       " 0.011128155697553987,\n",
       " 0.010942661505645379,\n",
       " 0.010940480867931757,\n",
       " 0.010821951101378735,\n",
       " 0.01082110640801881,\n",
       " 0.010855069327716738,\n",
       " 0.01085480205800371,\n",
       " 0.010690732544953896,\n",
       " 0.01069892686355034,\n",
       " 0.010953276432457137,\n",
       " 0.010943850674756561,\n",
       " 0.011090553190461705,\n",
       " 0.011092167752723703,\n",
       " 0.01110309646627583,\n",
       " 0.011098444630145199,\n",
       " 0.010866789442236513,\n",
       " 0.0108624850299196,\n",
       " 0.011057971455407878,\n",
       " 0.011061810130450489,\n",
       " 0.011162633814659983,\n",
       " 0.011155735122994725,\n",
       " 0.010957421179726978,\n",
       " 0.010946772642351443,\n",
       " 0.010841424819115542,\n",
       " 0.01083883746528258,\n",
       " 0.010515737281298954,\n",
       " 0.010511454425421674,\n",
       " 0.010710309933820827,\n",
       " 0.010704288313241106,\n",
       " 0.010538143567983216,\n",
       " 0.01052830652871628,\n",
       " 0.010226765488340672,\n",
       " 0.010231486372718424,\n",
       " 0.01002522918225246,\n",
       " 0.010020936940307701,\n",
       " 0.009968210817441148,\n",
       " 0.009954159468985146,\n",
       " 0.009969385236392903,\n",
       " 0.00998300761915294,\n",
       " 0.010085056142018156,\n",
       " 0.010071922470923256,\n",
       " 0.010320339071559825,\n",
       " 0.010316779583953606,\n",
       " 0.010321500322593713,\n",
       " 0.010323992845748364,\n",
       " 0.010541170234481312,\n",
       " 0.010533313712401515,\n",
       " 0.010541305895851005,\n",
       " 0.010538895975405804,\n",
       " 0.010603234407594475,\n",
       " 0.010621157651785618,\n",
       " 0.010602683914592292,\n",
       " 0.010582927166730483,\n",
       " 0.010540855426366402,\n",
       " 0.010551021409603178,\n",
       " 0.01114115433075169,\n",
       " 0.011145057054334884,\n",
       " 0.011312311255996077,\n",
       " 0.011293744233860092,\n",
       " 0.011089596789780387,\n",
       " 0.011089294353740842,\n",
       " 0.011157850548998094,\n",
       " 0.011144262720437004,\n",
       " 0.01128460181913038,\n",
       " 0.011276284027835537,\n",
       " 0.011425653144703896,\n",
       " 0.011423950303505848,\n",
       " 0.01172040474141145,\n",
       " 0.011723846251043946,\n",
       " 0.011315706446269447,\n",
       " 0.011323421943993717,\n",
       " 0.011496223431638475,\n",
       " 0.01149645216546924,\n",
       " 0.010990188591343819,\n",
       " 0.01099346708696558,\n",
       " 0.010870446612759821,\n",
       " 0.010891103683708936,\n",
       " 0.010698879133761108,\n",
       " 0.010703447719039971,\n",
       " 0.010677233524130747,\n",
       " 0.010675223185990346,\n",
       " 0.010643474732295433,\n",
       " 0.010641802244273246,\n",
       " 0.010472893680786521,\n",
       " 0.010475027344892585,\n",
       " 0.010432674245662521,\n",
       " 0.010437456456366845,\n",
       " 0.010822686788793057,\n",
       " 0.010816322081468988,\n",
       " 0.010447392583394888,\n",
       " 0.010450578003848077,\n",
       " 0.010418491809188302,\n",
       " 0.010425226098500828,\n",
       " 0.010473800745208428,\n",
       " 0.010475104967092252,\n",
       " 0.010558710103101943,\n",
       " 0.010564228213452598,\n",
       " 0.010325811131340457,\n",
       " 0.01031597905462256,\n",
       " 0.00985052214146509,\n",
       " 0.009867114580109249,\n",
       " 0.009565685373381094,\n",
       " 0.009562156164771407,\n",
       " 0.0091676562119557,\n",
       " 0.009173862818342537,\n",
       " 0.009338165238963247,\n",
       " 0.009340082723518495,\n",
       " 0.008952698585782293,\n",
       " 0.008959533476778692,\n",
       " 0.009239961084274162,\n",
       " 0.009225511177135104,\n",
       " 0.00939125778284311,\n",
       " 0.009389207213679307,\n",
       " 0.009453610268766344,\n",
       " 0.009458404220947347,\n",
       " 0.009074571598449932,\n",
       " 0.009068556678004103,\n",
       " 0.008950521389912813,\n",
       " 0.008947266454270464,\n",
       " 0.00865333067184293,\n",
       " 0.00864627607205981,\n",
       " 0.00844704486926351,\n",
       " 0.008447279544122832,\n",
       " 0.008230960033223655,\n",
       " 0.008230324319755788,\n",
       " 0.008468378171420876,\n",
       " 0.008473224440943894,\n",
       " 0.008750071802178905,\n",
       " 0.008743890816826139,\n",
       " 0.008845287869640783,\n",
       " 0.008845974744907004,\n",
       " 0.008852846305145823,\n",
       " 0.008853831381252064,\n",
       " 0.008722562946009815,\n",
       " 0.00872395064683218,\n",
       " 0.008292800988993543,\n",
       " 0.0082969027737132,\n",
       " 0.007956372042645432,\n",
       " 0.007951794583018534,\n",
       " 0.007560953169375106,\n",
       " 0.007552477209210595,\n",
       " 0.007373736060540148,\n",
       " 0.0073763005665105075,\n",
       " 0.007307134197804821,\n",
       " 0.00730388333178511,\n",
       " 0.007368225459471578,\n",
       " 0.007359995102194539,\n",
       " 0.007060619120255129,\n",
       " 0.007052476649320738,\n",
       " 0.0073267388074595985,\n",
       " 0.007328621099213617,\n",
       " 0.007730549038984846,\n",
       " 0.00773212160756831,\n",
       " 0.007733140866152177]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np        \n",
    "f=open('065014LORO.txt','a')\n",
    "np.savetxt(f, error_reward, fmt='%1.3f', newline=\", \")\n",
    "f.write(\"\\n\")\n",
    "np.savetxt(f, error_best_choosen, fmt='%1.3f', newline=\", \")\n",
    "f.write(\"\\n\")\n",
    "np.savetxt(f, sample_correct, fmt='%1.3f', newline=\", \")\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
